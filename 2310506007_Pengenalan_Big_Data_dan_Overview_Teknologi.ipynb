{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c25d6f",
   "metadata": {
    "id": "10c25d6f"
   },
   "source": [
    "# Hands-On Pertemuan 1: Pengenalan Big Data dan Overview Teknologi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117dfdb",
   "metadata": {
    "id": "7117dfdb"
   },
   "source": [
    "## Tujuan\n",
    "Pada akhir praktikum ini, mahasiswa diharapkan mampu:\n",
    "1. Memahami konsep dasar Big Data.\n",
    "2. Menjelaskan karakteristik dan tantangan Big Data (Volume, Variety, Velocity, dan Veracity).\n",
    "3. Mengenal teknologi yang digunakan dalam ekosistem Big Data.\n",
    "4. Menginstal dan mengonfigurasi Anaconda untuk bekerja dengan alat Big Data seperti Hadoop dan Spark.\n",
    "5. Memulai praktik sederhana terkait pengolahan data menggunakan PySpark dan Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e805141",
   "metadata": {
    "id": "7e805141"
   },
   "source": [
    "## Peralatan yang Dibutuhkan\n",
    "1. Anaconda (untuk manajemen lingkungan)\n",
    "2. Jupyter Notebook (bawaan dari Anaconda)\n",
    "3. PySpark (untuk pemrosesan data skala besar)\n",
    "4. Pandas (untuk data analysis)\n",
    "5. Python (bawaan dari Anaconda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa78a0",
   "metadata": {
    "id": "8daa78a0"
   },
   "source": [
    "## Langkah-Langkah Hands-On"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b963c0",
   "metadata": {
    "id": "23b963c0"
   },
   "source": [
    "### 1. Instalasi Anaconda\n",
    "- **Langkah 1: Unduh dan Instal Anaconda**\n",
    "  Anaconda adalah platform distribusi Python yang menyertakan berbagai alat pengembangan, termasuk Jupyter Notebook. Ikuti langkah-langkah instalasi sesuai sistem operasi:\n",
    "  - Unduh Anaconda: [Download Anaconda](https://www.anaconda.com/products/individual)\n",
    "  - Instal sesuai instruksi yang ada di situs web tersebut (Windows/Mac/Linux).\n",
    "\n",
    "- **Langkah 2: Menginstal PySpark di Anaconda**\n",
    "  Setelah Anaconda terinstal, tambahkan PySpark:\n",
    "  ```bash\n",
    "  pip install pyspark==3.4.1\n",
    "  ```\n",
    "\n",
    "- **Langkah 3: Menginstal Pandas**\n",
    "  Untuk memudahkan data analysis, install Pandas:\n",
    "  ```bash\n",
    "  pip install pandas\n",
    "  ```\n",
    "\n",
    "- **Langkah 4: Menginstal Findspark**\n",
    "  ```bash\n",
    "  pip install findspark\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f1a45",
   "metadata": {
    "id": "208f1a45"
   },
   "source": [
    "### 2. Pengenalan dan Praktik Dasar PySpark dan Pandas\n",
    "- **Langkah 1: Membuka Jupyter Notebook**\n",
    "  Setelah instalasi selesai, buka Jupyter Notebook melalui Anaconda Navigator atau melalui terminal dengan perintah:\n",
    "  ```bash\n",
    "  jupyter notebook\n",
    "  ```\n",
    "\n",
    "- **Langkah 2: Membuat Project Notebook Baru**\n",
    "  Di Jupyter Notebook, buat notebook baru untuk praktikum ini.\n",
    "\n",
    "- **Langkah 3: Praktik dengan PySpark**\n",
    "  Buat program sederhana untuk memulai dengan PySpark. Gunakan PySpark untuk membuat DataFrame dan memanipulasi data sederhana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "KERSZShIH_aN",
   "metadata": {
    "id": "KERSZShIH_aN"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b447146-8bd8-43d3-816e-84786c2242b0",
   "metadata": {
    "id": "8747276f"
   },
   "source": [
    "- **Tugas 1**: Jalankan kode di atas dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a8e720d-77b9-4b74-8a97-e727ef433ef1",
   "metadata": {
    "id": "f78a5053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "+-----+----+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34, \"PNS\", \"Renang\", \"Pria\"), (\"Budi\", 23,\"Atlit\", \"Lari\", \"Pria\"), (\"Citra\", 29,\"Guru\", \"Hiking\", \"Wanita\"), (\"Dina\", 45,\"Freelancer\", \"Berkebun\", \"Wanita\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeca92c-91dc-47c9-9667-e97190c6b186",
   "metadata": {
    "id": "f78a5053"
   },
   "source": [
    "\r\n",
    "1. **Memulai Spark Session**:  \r\n",
    "   - `SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()` - Membuat dan mengonfigurasi sesi Spark dengan nama aplikasi \"BigDataPractice\".\r\n",
    "\r\n",
    "2. **Membuat DataFrame**:  \r\n",
    "   - Data: Daftar tuple berisi data individu dengan informasi nama, usia, pekerjaan, hobi, dan gender.  \r\n",
    "   - Kolom: Daftar nama kolom yang sesuai dengan data.\r\n",
    "\r\n",
    "3. **Menampilkan DataFrame**:  \r\n",
    "   - `df.show()` - Menampilkan DataFrame di console dengan format tabular.t tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d419838-d57a-4ba2-b91a-69175cbe1152",
   "metadata": {
    "id": "f78a5053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+\n",
      "| Nama|Usia| Pekerjaan|\n",
      "+-----+----+----------+\n",
      "|  Ali|  34|       PNS|\n",
      "| Budi|  23|     Atlit|\n",
      "|Citra|  29|      Guru|\n",
      "| Dina|  45|Freelancer|\n",
      "+-----+----+----------+\n",
      "\n",
      "+-----+----+----------+--------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|\n",
      "+-----+----+----------+--------+\n",
      "|  Ali|  34|       PNS|  Renang|\n",
      "| Budi|  23|     Atlit|    Lari|\n",
      "|Citra|  29|      Guru|  Hiking|\n",
      "| Dina|  45|Freelancer|Berkebun|\n",
      "+-----+----+----------+--------+\n",
      "\n",
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "+-----+----+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, when\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana dengan dua kolom\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menambahkan kolom \"Pekerjaan\"\n",
    "df = df.withColumn(\"Pekerjaan\", when(df[\"Nama\"] == \"Ali\", \"PNS\")\n",
    "                                .when(df[\"Nama\"] == \"Budi\", \"Atlit\")\n",
    "                                .when(df[\"Nama\"] == \"Citra\", \"Guru\")\n",
    "                                .when(df[\"Nama\"] == \"Dina\", \"Freelancer\"))\n",
    "df.show()\n",
    "\n",
    "# Menambahkan kolom \"Hobi\"\n",
    "df = df.withColumn(\"Hobi\", when(df[\"Nama\"] == \"Ali\", \"Renang\")\n",
    "                            .when(df[\"Nama\"] == \"Budi\", \"Lari\")\n",
    "                            .when(df[\"Nama\"] == \"Citra\", \"Hiking\")\n",
    "                            .when(df[\"Nama\"] == \"Dina\", \"Berkebun\"))\n",
    "df.show()\n",
    "\n",
    "# Menambahkan kolom \"Gender\"\n",
    "df = df.withColumn(\"Gender\", when(df[\"Nama\"] == \"Ali\", \"Pria\")\n",
    "                              .when(df[\"Nama\"] == \"Budi\", \"Pria\")\n",
    "                              .when(df[\"Nama\"] == \"Citra\", \"Wanita\")\n",
    "                              .when(df[\"Nama\"] == \"Dina\", \"Wanita\"))\n",
    "\n",
    "# Menampilkan DataFrame akhir\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f56ac7c-41df-4c60-95b3-5dae5d00c083",
   "metadata": {
    "id": "8747276f"
   },
   "source": [
    "\r\n",
    "1. **Memulai Spark Session**:  \r\n",
    "   - `SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()` - Membuat dan mengonfigurasi sesi Spark.\r\n",
    "\r\n",
    "2. **Membuat DataFrame Awal**:  \r\n",
    "   - `data`: Daftar tuple dengan nama dan usia.  \r\n",
    "   - `columns`: \"Nama\" dan \"Usia\".\r\n",
    "\r\n",
    "3. **Menambahkan Kolom \"Pekerjaan\"**:  \r\n",
    "   - Menggunakan fungsi `when` untuk menetapkan nilai pekerjaan berdasarkan nama.\r\n",
    "\r\n",
    "4. **Menambahkan Kolom \"Hobi\"**:  \r\n",
    "   - Menggunakan fungsi `when` untuk menetapkan nilai hobi berdasarkan nama.\r\n",
    "\r\n",
    "5. **Menambahkan Kolom \"Gender\"**:  \r\n",
    "   - Menggunakan fungsi `when` untuk menetapkan nilai gender berdasarkan nama.\r\n",
    "\r\n",
    "6. **Menampilkan DataFrame Akhir**:  \r\n",
    "   - `df.show()` - Menampilkan DataFrame setelah semua kolom tambahan (\"Pekerjaan\", \"Hobi\", dan \"Gender\") ditambahkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84a333",
   "metadata": {
    "id": "1f84a333"
   },
   "source": [
    "### 3. Praktik PySpark Lanjutan\n",
    "- **Latihan 1**: Memanipulasi Data dengan PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06767bc",
   "metadata": {
    "id": "e06767bc"
   },
   "source": [
    "- **Tugas 2**: Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e8eef1-f43b-4bf4-a6fb-4b0d89b3f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame asli:\n",
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "+-----+----+----------+--------+------+\n",
      "\n",
      "Data setelah difilter (Usia > 30):\n",
      "+----+----+----------+--------+------+\n",
      "|Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+----+----+----------+--------+------+\n",
      "| Ali|  34|       PNS|  Renang|  Pria|\n",
      "|Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "+----+----+----------+--------+------+\n",
      "\n",
      "Rata-rata Usia:\n",
      "+---------+\n",
      "|avg(Usia)|\n",
      "+---------+\n",
      "|    32.75|\n",
      "+---------+\n",
      "\n",
      "Data diurutkan berdasarkan Nama (ascending):\n",
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "+-----+----+----------+--------+------+\n",
      "\n",
      "Data diurutkan berdasarkan Usia (ascending):\n",
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "+-----+----+----------+--------+------+\n",
      "\n",
      "Data diurutkan berdasarkan Pekerjaan (ascending):\n",
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "+-----+----+----------+--------+------+\n",
      "\n",
      "Data diurutkan berdasarkan Hobi (ascending):\n",
      "+-----+----+----------+--------+------+\n",
      "| Nama|Usia| Pekerjaan|    Hobi|Gender|\n",
      "+-----+----+----------+--------+------+\n",
      "| Dina|  45|Freelancer|Berkebun|Wanita|\n",
      "|Citra|  29|      Guru|  Hiking|Wanita|\n",
      "| Budi|  23|     Atlit|    Lari|  Pria|\n",
      "|  Ali|  34|       PNS|  Renang|  Pria|\n",
      "+-----+----+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34, \"PNS\", \"Renang\", \"Pria\"), \n",
    "        (\"Budi\", 23, \"Atlit\", \"Lari\", \"Pria\"), \n",
    "        (\"Citra\", 29, \"Guru\", \"Hiking\", \"Wanita\"), \n",
    "        (\"Dina\", 45, \"Freelancer\", \"Berkebun\", \"Wanita\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame asli\n",
    "print(\"DataFrame asli:\")\n",
    "df.show()\n",
    "\n",
    "# Filtering data (Usia > 30)\n",
    "df_filtered = df.filter(df['Usia'] > 30)\n",
    "print(\"Data setelah difilter (Usia > 30):\")\n",
    "df_filtered.show()\n",
    "\n",
    "# Menghitung rata-rata usia\n",
    "print(\"Rata-rata Usia:\")\n",
    "df.groupBy().agg(avg(\"Usia\")).show()\n",
    "\n",
    "# Mengurutkan data berdasarkan Nama\n",
    "print(\"Data diurutkan berdasarkan Nama (ascending):\")\n",
    "df_sorted_by_nama = df.orderBy(\"Nama\", ascending=True)\n",
    "df_sorted_by_nama.show()\n",
    "\n",
    "# Mengurutkan data berdasarkan Usia\n",
    "print(\"Data diurutkan berdasarkan Usia (ascending):\")\n",
    "df_sorted_by_usia = df.orderBy(\"Usia\", ascending=True)\n",
    "df_sorted_by_usia.show()\n",
    "\n",
    "# Mengurutkan data berdasarkan Pekerjaan\n",
    "print(\"Data diurutkan berdasarkan Pekerjaan (ascending):\")\n",
    "df_sorted_by_pekerjaan = df.orderBy(\"Pekerjaan\", ascending=True)\n",
    "df_sorted_by_pekerjaan.show()\n",
    "\n",
    "# Mengurutkan data berdasarkan Hobi\n",
    "print(\"Data diurutkan berdasarkan Hobi (ascending):\")\n",
    "df_sorted_by_hobi = df.orderBy(\"Hobi\", ascending=True)\n",
    "df_sorted_by_hobi.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c75c4-149d-4b0e-9baf-bdd1e5dc3606",
   "metadata": {},
   "source": [
    "\r\n",
    "1. **Memulai Spark Session**:  \r\n",
    "   - `SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()` - Membuat sesi Spark dengan nama aplikasi \"BigDataPractice\".\r\n",
    "\r\n",
    "2. **Membuat DataFrame**:  \r\n",
    "   - `data`: Daftar tuple yang berisi nama, usia, pekerjaan, hobi, dan gender.  \r\n",
    "   - `columns`: Kolom \"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\".\r\n",
    "\r\n",
    "3. **Menampilkan DataFrame Asli**:  \r\n",
    "   - `df.show()` - Menampilkan DataFrame awal.\r\n",
    "\r\n",
    "4. **Filtering Data**:  \r\n",
    "   - Menggunakan filter untuk memilih baris dengan usia lebih dari 30 tahun.  \r\n",
    "   - Menampilkan hasil filter dengan `df_filtered.show()`.\r\n",
    "\r\n",
    "5. **Menghitung Rata-Rata Usia**:  \r\n",
    "   - Menggunakan `groupBy().agg(avg(\"Usia\"))` untuk menghitung rata-rata usia dari DataFrame.\r\n",
    "\r\n",
    "6. **Mengurutkan Data**:  \r\n",
    "   - Berdasarkan Nama: `df.orderBy(\"Nama\", ascending=True)`  \r\n",
    "   - Berdasarkan Usia: `df.orderBy(\"Usia\", ascending=True)`  \r\n",
    "   - Berdasarkan Pekerjaan: `df.orderBy(\"Pekerjaan\", ascending=True)`  \r\n",
    "   - Berdasarkan Hobi: `df.orderBy(\"Hobi\", ascending=True)`  \r\n",
    "   - Menampilkan DataFrame yang telah diurutkan sesuai dengan kriteria yang ditentukan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e34a5",
   "metadata": {
    "id": "fe1e34a5"
   },
   "source": [
    "### 4. Praktik dengan Pandas\n",
    "- **Latihan 2**:  Buat DataFrame menggunakan Pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4dbf05-030d-4666-9336-7bb767035973",
   "metadata": {
    "id": "9da455f1"
   },
   "source": [
    "- **Tugas 3**: Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ed5db9b-bb40-42b9-95e6-46e92cb9ae6a",
   "metadata": {
    "id": "9da455f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame setelah penambahan kolom 'Status':\n",
      "    Nama  Usia   Pekerjaan      Hobi  Gender      Status\n",
      "0    Ali    34         PNS    Renang    Pria  di atas 30\n",
      "1   Budi    23       Atlit      Lari    Pria    di bawah\n",
      "2  Citra    29        Guru    Hiking  Wanita    di bawah\n",
      "3   Dina    45  Freelancer  Berkebun  Wanita  di atas 30\n",
      "\n",
      "DataFrame setelah filtering usia di atas 30:\n",
      "   Nama  Usia   Pekerjaan      Hobi  Gender      Status\n",
      "0   Ali    34         PNS    Renang    Pria  di atas 30\n",
      "3  Dina    45  Freelancer  Berkebun  Wanita  di atas 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data = [(\"Ali\", 34, \"PNS\", \"Renang\", \"Pria\"), \n",
    "        (\"Budi\", 23, \"Atlit\", \"Lari\", \"Pria\"), \n",
    "        (\"Citra\", 29, \"Guru\", \"Hiking\", \"Wanita\"), \n",
    "        (\"Dina\", 45, \"Freelancer\", \"Berkebun\", \"Wanita\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df_pandas = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Menambahkan kolom baru \"Status\"\n",
    "df_pandas['Status'] = df_pandas['Usia'].apply(lambda usia: 'di atas 30' if usia > 30 else 'di bawah')\n",
    "\n",
    "# Menampilkan DataFrame setelah penambahan kolom\n",
    "print(\"DataFrame setelah penambahan kolom 'Status':\")\n",
    "print(df_pandas)\n",
    "\n",
    "# Filtering data untuk usia di atas 30\n",
    "df_filtered = df_pandas[df_pandas['Usia'] > 30]\n",
    "\n",
    "# Menampilkan DataFrame setelah filtering\n",
    "print(\"\\nDataFrame setelah filtering usia di atas 30:\")\n",
    "print(df_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d5f31-8652-489c-8117-59f39924668c",
   "metadata": {
    "id": "9da455f1"
   },
   "source": [
    "\r\n",
    "1. **Membuat DataFrame**:  \r\n",
    "   - `data`: Daftar tuple dengan nama, usia, pekerjaan, hobi, dan gender.  \r\n",
    "   - `columns`: Daftar nama kolom.  \r\n",
    "   - `df_pandas`: DataFrame dengan kolom-kolom yang ditentukan.\r\n",
    "\r\n",
    "2. **Menambahkan Kolom Baru \"Status\"**:  \r\n",
    "   - Menggunakan `apply` dengan fungsi lambda untuk menambahkan kolom \"Status\".  \r\n",
    "   - Fungsi lambda menetapkan nilai \"di atas 30\" jika usia lebih dari 30 dan \"di bawah\" jika tidak.\r\n",
    "\r\n",
    "3. **Menampilkan DataFrame Setelah Penambahan Kolom**:  \r\n",
    "   - `print(df_pandas)` - Menampilkan DataFrame dengan kolom \"Status\" yang baru ditambahkan.\r\n",
    "\r\n",
    "4. **Filtering Data untuk Usia di Atas 30**:  \r\n",
    "   - `df_filtered = df_pandas[df_pandas['Usia'] > 30]` - Memilih baris dengan usia lebih dari 30.\r\n",
    "\r\n",
    "5. **Menampilkan DataFrame Setelah Filtering**:  \r\n",
    "   - `print(df_filtered)` - Menampilkan DataFrame yang hanya berisi baris dengan usia di atas 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0042b2b",
   "metadata": {
    "id": "c0042b2b"
   },
   "source": [
    "### 5. Praktik Pandas Lanjutan\n",
    "- **Latihan 3**: Penggunaan Pandas untuk operasi lebih kompleks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a8c539-b226-4963-93db-672cf89266cc",
   "metadata": {
    "id": "884ed75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame setelah penggabungan:\n",
      "    Nama  Usia Pekerjaan\n",
      "0    Ali    34    Dokter\n",
      "1   Budi    23      Guru\n",
      "2  Citra    29  Insinyur\n",
      "3   Dina    45   Perawat\n",
      "\n",
      "Statistik Deskriptif:\n",
      "            Usia\n",
      "count   4.000000\n",
      "mean   32.750000\n",
      "std     9.322911\n",
      "min    23.000000\n",
      "25%    27.500000\n",
      "50%    31.500000\n",
      "75%    36.750000\n",
      "max    45.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Membuat DataFrame Pandas pertama\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame Pandas kedua\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Menggabungkan kedua DataFrame berdasarkan kolom \"Nama\"\n",
    "df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\")\n",
    "\n",
    "# Menampilkan DataFrame hasil penggabungan\n",
    "print(\"DataFrame setelah penggabungan:\")\n",
    "print(df_joined)\n",
    "\n",
    "# Menghitung statistik deskriptif\n",
    "print(\"\\nStatistik Deskriptif:\")\n",
    "print(df_pandas.describe())\n",
    "\n",
    "# Membuat plot bar dari kolom 'Usia'\n",
    "df_pandas['Usia'].plot(kind='bar', title='Usia')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Usia')\n",
    "plt.xticks(rotation=0)  # Rotasi label x-axis agar tidak miring\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52b910-b7cf-490c-8911-adfac48cc93a",
   "metadata": {
    "id": "884ed75d"
   },
   "source": [
    "\r\n",
    "1. **Membuat DataFrame Pandas Pertama**:  \r\n",
    "   - `data_pandas`: Data tentang nama dan usia.  \r\n",
    "   - `df_pandas`: DataFrame pertama dengan kolom \"Nama\" dan \"Usia\".\r\n",
    "\r\n",
    "2. **Membuat DataFrame Pandas Kedua**:  \r\n",
    "   - `data_pandas_2`: Data tentang nama dan pekerjaan.  \r\n",
    "   - `df_pandas_2`: DataFrame kedua dengan kolom \"Nama\" dan \"Pekerjaan\".\r\n",
    "\r\n",
    "3. **Menggabungkan DataFrame**:  \r\n",
    "   - `pd.merge(df_pandas, df_pandas_2, on=\"Nama\")`: Menggabungkan kedua DataFrame berdasarkan kolom \"Nama\".\r\n",
    "\r\n",
    "4. **Menampilkan DataFrame Hasil Penggabungan**:  \r\n",
    "   - `print(df_joined)` - Menampilkan DataFrame setelah penggabungan.\r\n",
    "\r\n",
    "5. **Menghitung Statistik Deskriptif**:  \r\n",
    "   - `df_pandas.describe()` - Menghitung statistik deskriptif (seperti count, mean, std, min, max) dari DataFrame `df_pandas`.\r\n",
    "\r\n",
    "6. **Membuat Plot Bar**:  \r\n",
    "   - `df_pandas['Usia'].plot(kind='bar', title='Usia')`: Membuat plot bar untuk kolom \"Usia\".  \r\n",
    "   - `plt.xlabel('Index')`: Menambahkan label pada sumbu x.  \r\n",
    "   - `plt.ylabel('Usia')`: Menambahkan label pada sumbu y.  \r\n",
    "   - `plt.xticks(rotation=0)`: Menjaga label sumbu x tetap horizontal.  \r\n",
    "   - `plt.show()` - Menampilkan plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1cf3b-fb95-407b-949f-76fb58381821",
   "metadata": {
    "id": "884ed75d"
   },
   "source": [
    "- **Tugas 4**: Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf671ba3",
   "metadata": {
    "id": "bf671ba3"
   },
   "source": [
    "### 5. Menggabungkan PySpark dan Pandas\n",
    "- **Latihan 4: Mengonversi DataFrame antara PySpark dan Pandas**\n",
    "  Praktik untuk convert DataFrame dari PySpark ke Pandas dan sebaliknya:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba4e5c",
   "metadata": {
    "id": "2cba4e5c"
   },
   "source": [
    "- **Tugas 5**: Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e4ce2e9-4339-432e-b4cf-03f5ed184230",
   "metadata": {
    "id": "337e123f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Gabungan (PySpark dan Pandas):\n",
      "      Nama  Usia   Pekerjaan             Hobi  Gender\n",
      "0      Ali    34         PNS           Renang    Pria\n",
      "1     Budi    23       Atlit             Lari    Pria\n",
      "2    Citra    29        Guru           Hiking  Wanita\n",
      "3     Dina    45  Freelancer         Berkebun  Wanita\n",
      "4    Enril    23     Aktivis  Public Speaking    Pria\n",
      "5  Faruzan    33   Pengacara          Membaca  Wanita\n",
      "\n",
      "Rata-rata Usia: 31.166666666666668\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Data PySpark\n",
    "data_spark = [(\"Ali\", 34, \"PNS\", \"Renang\", \"Pria\"), \n",
    "              (\"Budi\", 23, \"Atlit\", \"Lari\", \"Pria\"), \n",
    "              (\"Citra\", 29, \"Guru\", \"Hiking\", \"Wanita\"), \n",
    "              (\"Dina\", 45, \"Freelancer\", \"Berkebun\", \"Wanita\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df_spark = spark.createDataFrame(data_spark, schema=columns)\n",
    "\n",
    "# Data Pandas\n",
    "data_pandas = {\n",
    "    \"Nama\": [\"Enril\", \"Faruzan\"],\n",
    "    \"Usia\": [23, 33],\n",
    "    \"Pekerjaan\": [\"Aktivis\", \"Pengacara\"],\n",
    "    \"Hobi\": [\"Public Speaking\", \"Membaca\"],\n",
    "    \"Gender\": [\"Pria\", \"Wanita\"]\n",
    "}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menggabungkan Data dari PySpark dan Pandas\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "df_combined = df_spark.union(df_spark_from_pandas)\n",
    "\n",
    "# Mengonversi DataFrame PySpark ke Pandas untuk Analisis Lebih Lanjut\n",
    "df_combined_pandas = df_combined.toPandas()\n",
    "\n",
    "# Analisis: Menghitung Rata-rata Usia\n",
    "average_age = df_combined_pandas[\"Usia\"].mean()\n",
    "\n",
    "print(\"DataFrame Gabungan (PySpark dan Pandas):\")\n",
    "print(df_combined_pandas)\n",
    "\n",
    "print(f\"\\nRata-rata Usia: {average_age}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee1a51-cf41-4571-bbc4-096bff5da32c",
   "metadata": {
    "id": "337e123f"
   },
   "source": [
    "\r\n",
    "1. **Inisialisasi Spark**:  \r\n",
    "   `findspark.init()` - Menginisialisasi Spark.  \r\n",
    "   `SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()` - Membuat sesi Spark dengan nama aplikasi \"BigDataPractice\".\r\n",
    "\r\n",
    "2. **Membuat DataFrame PySpark**:  \r\n",
    "   `data_spark` dan `columns` - Data dan kolom untuk DataFrame PySpark.  \r\n",
    "   `df_spark = spark.createDataFrame(data_spark, schema=columns)` - Membuat DataFrame PySpark.\r\n",
    "\r\n",
    "3. **Membuat DataFrame Pandas**:  \r\n",
    "   `data_pandas` - Data untuk DataFrame Pandas.  \r\n",
    "   `df_pandas = pd.DataFrame(data_pandas)` - Membuat DataFrame Pandas.\r\n",
    "\r\n",
    "4. **Mengonversi DataFrame dari Pandas ke PySpark**:  \r\n",
    "   `df_spark_from_pandas = spark.createDataFrame(df_pandas)` - Mengonversi DataFrame Pandas ke DataFrame PySpark.  \r\n",
    "   `df_combined = df_spark.union(df_spark_from_pandas)` - Menggabungkan DataFrame PySpark dari data PySpark dan Pandas.\r\n",
    "\r\n",
    "5. **Mengonversi DataFrame PySpark ke Pandas**:  \r\n",
    "   `df_combined_pandas = df_combined.toPandas()` - Mengonversi DataFrame PySpark yang digabungkan ke DataFrame Pandas untuk analisis lebih lanjut.\r\n",
    "\r\n",
    "6. **Analisis Data**:  \r\n",
    "   `average_age = df_combined_pandas[\"Usia\"].mean()` - Menghitung rata-rata usia.\r\n",
    "\r\n",
    "7. **Menampilkan Hasil**:  \r\n",
    "   `print(df_combined_pandas)` - Menampilkan DataFrame gabungan.  \r\n",
    "   `print(f\"\\nRata-rata Usia: {average_age}\")` - Menampilkan rata-rata usia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdba6be",
   "metadata": {
    "id": "afdba6be"
   },
   "source": [
    "### 6. Konversi Data antara PySpark dan Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65adbe71",
   "metadata": {
    "id": "65adbe71"
   },
   "source": [
    "- **Tugas 6**: Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716600bc-7734-4d3e-8f52-8473281426f0",
   "metadata": {
    "id": "f863defc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame dari PySpark ke Pandas:\n",
      "    Nama  Usia   Pekerjaan      Hobi  Gender\n",
      "0    Ali    34         PNS    Renang    Pria\n",
      "1   Budi    23       Atlit      Lari    Pria\n",
      "2  Citra    29        Guru    Hiking  Wanita\n",
      "3   Dina    45  Freelancer  Berkebun  Wanita\n",
      "\n",
      "DataFrame dari Pandas ke PySpark:\n",
      "+-------+----+---------+---------------+------+\n",
      "|   Nama|Usia|Pekerjaan|           Hobi|Gender|\n",
      "+-------+----+---------+---------------+------+\n",
      "|  Enril|  23|  Aktivis|Public Speaking|  Pria|\n",
      "|Faruzan|  33|Pengacara|        Membaca|Wanita|\n",
      "+-------+----+---------+---------------+------+\n",
      "\n",
      "\n",
      "Nilai maksimum usia dari DataFrame gabungan: 45\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Data PySpark\n",
    "data_spark = [(\"Ali\", 34, \"PNS\", \"Renang\", \"Pria\"), \n",
    "              (\"Budi\", 23, \"Atlit\", \"Lari\", \"Pria\"), \n",
    "              (\"Citra\", 29, \"Guru\", \"Hiking\", \"Wanita\"), \n",
    "              (\"Dina\", 45, \"Freelancer\", \"Berkebun\", \"Wanita\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df_spark = spark.createDataFrame(data_spark, schema=columns)\n",
    "\n",
    "# Data Pandas\n",
    "data_pandas = {\n",
    "    \"Nama\": [\"Enril\", \"Faruzan\"],\n",
    "    \"Usia\": [23, 33],\n",
    "    \"Pekerjaan\": [\"Aktivis\", \"Pengacara\"],\n",
    "    \"Hobi\": [\"Public Speaking\", \"Membaca\"],\n",
    "    \"Gender\": [\"Pria\", \"Wanita\"]\n",
    "}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df_spark.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "print(\"DataFrame dari PySpark ke Pandas:\")\n",
    "print(df_pandas_from_spark)\n",
    "\n",
    "print(\"\\nDataFrame dari Pandas ke PySpark:\")\n",
    "df_spark_from_pandas.show()\n",
    "\n",
    "# Menggabungkan Data dari PySpark dan Pandas\n",
    "df_combined = df_spark.union(df_spark_from_pandas)\n",
    "\n",
    "# Melakukan operasi statistik: Menghitung nilai maksimum usia\n",
    "max_age = df_combined.agg({\"Usia\": \"max\"}).collect()[0][0]\n",
    "\n",
    "print(f\"\\nNilai maksimum usia dari DataFrame gabungan: {max_age}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20541a03-9e6c-41fc-b3df-b6e2ebf599f9",
   "metadata": {},
   "source": [
    "1. **Inisialisasi Spark**:\n",
    "   - `findspark.init()` - Menginisialisasi Spark.\n",
    "   - `SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()` - Membuat sesi Spark dengan nama aplikasi \"BigDataPractice\".\n",
    "\n",
    "2. **Membuat DataFrame PySpark**:\n",
    "   - `data_spark` dan `columns` - Data dan kolom untuk DataFrame PySpark.\n",
    "   - `df_spark = spark.createDataFrame(data_spark, schema=columns)` - Membuat DataFrame PySpark.\n",
    "\n",
    "3. **Membuat DataFrame Pandas**:\n",
    "   - `data_pandas` - Data untuk DataFrame Pandas.\n",
    "   - `df_pandas = pd.DataFrame(data_pandas)` - Membuat DataFrame Pandas.\n",
    "\n",
    "4. **Mengonversi DataFrame dari PySpark ke Pandas**:\n",
    "   - `df_pandas_from_spark = df_spark.toPandas()` - Mengonversi DataFrame PySpark ke DataFrame Pandas.\n",
    "\n",
    "5. **Mengonversi DataFrame dari Pandas ke PySpark**:\n",
    "   - `df_spark_from_pandas = spark.createDataFrame(df_pandas)` - Mengonversi DataFrame Pandas ke DataFrame PySpark.\n",
    "\n",
    "6. **Menampilkan DataFrame Hasil Konversi**:\n",
    "   - `print(df_pandas_from_spark)` - Menampilkan DataFrame Pandas hasil konversi dari PySpark.\n",
    "   - `df_spark_from_pandas.show()` - Menampilkan DataFrame PySpark hasil konversi dari Pandas.\n",
    "\n",
    "7. **Menggabungkan DataFrame**:\n",
    "   - `df_combined = df_spark.union(df_spark_from_pandas)` - Menggabungkan DataFrame PySpark dari data PySpark dan data yang dikonversi dari Pandas.\n",
    "\n",
    "8. **Operasi Statistik**:\n",
    "   - `max_age = df_combined.agg({\"Usia\": \"max\"}).collect()[0][0]` - Menghitung nilai maksimum usia dari DataFrame gabungan.\n",
    "\n",
    "9. **Menampilkan Hasil**:\n",
    "   - `print(f\"\\nNilai maksimum usia dari DataFrame gabungan: {max_age}\")` - Menampilkan nilai maksimum usia dari DataFrame gabungan.\n",
    "\n",
    "Ini menunjukkan integrasi antara PySpark dan Pandas, serta bagaimana mengonversi, menggabungkan, dan melakukan analisis statistik pada data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
