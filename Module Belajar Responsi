# Langkah 1: Instal paket yang diperlukan
!pip install pyspark findspark pandas matplotlib

# Langkah 2: Menginisialisasi findspark dan mengimpor library yang diperlukan
import findspark
findspark.init()

from pyspark.sql import SparkSession
from pyspark.sql.functions import split, col, min, max
import matplotlib.pyplot as plt

# Langkah 3: Inisialisasi Spark Session
spark = SparkSession.builder \
    .appName("Data Karyawan") \
    .getOrCreate()

# Langkah 4: Membuat DataFrame dengan data karyawan
data_karyawan = [
    ("Alice", "Engineer", 60000, "21-08-2004"),
    ("Bob", "Designer", 55000, "15-05-2010"),
    ("Charlie", "Manager", 80000, "30-12-2022"),
    ("David", "Analyst", 70000, "10-01-2018"),
    ("Eve", "Developer", 75000, "22-07-2019")
]
columns_karyawan = ["Nama", "Pekerjaan", "Gaji", "Tanggal"]
df_karyawan = spark.createDataFrame(data_karyawan, columns_karyawan)

# Langkah 5: Membuat DataFrame dengan data proyek
data_proyek = [
    ("Engineer", "Proyek A"),
    ("Designer", "Proyek B"),
    ("Manager", "Proyek C"),
    ("Analyst", "Proyek D"),
    ("Developer", "Proyek E")
]
columns_proyek = ["Pekerjaan", "Proyek"]
df_proyek = spark.createDataFrame(data_proyek, columns_proyek)

# Langkah 6: Join DataFrame karyawan dengan proyek berdasarkan pekerjaan
df_joined = df_karyawan.join(df_proyek, on="Pekerjaan", how="inner")

# Langkah 7: Memisahkan kolom tanggal menjadi hari, bulan, dan tahun
df_split = df_joined.withColumn("Hari", split(col("Tanggal"), "-").getItem(0)) \
                    .withColumn("Bulan", split(col("Tanggal"), "-").getItem(1)) \
                    .withColumn("Tahun", split(col("Tanggal"), "-").getItem(2))

# Langkah 8: Menampilkan DataFrame yang sudah digabungkan dan dipisahkan
df_split.show()

# Langkah 9: Menghitung nilai minimum dan maksimum gaji
min_gaji = df_split.select(min("Gaji")).collect()[0][0]
max_gaji = df_split.select(max("Gaji")).collect()[0][0]

print(f"Minimum Gaji: {min_gaji}")
print(f"Maksimum Gaji: {max_gaji}")

# Langkah 10: GroupBy pekerjaan dan menghitung rata-rata gaji
df_grouped = df_split.groupBy("Pekerjaan").avg("Gaji")
df_grouped.show()

# Langkah 11: Mengonversi DataFrame PySpark ke Pandas DataFrame untuk visualisasi
df_pandas = df_grouped.toPandas()

# Langkah 12: Visualisasi rata-rata gaji per pekerjaan menggunakan matplotlib
plt.figure(figsize=(8, 5))
plt.bar(df_pandas['Pekerjaan'], df_pandas['avg(Gaji)'], color='skyblue')
plt.xlabel('Pekerjaan')
plt.ylabel('Rata-rata Gaji')
plt.title('Rata-rata Gaji per Pekerjaan')
plt.show()

# Langkah 13: Menutup Spark Session
spark.stop()


Penjelasan Kode
Instalasi Paket:

1. !pip install pyspark findspark pandas matplotlib: Menginstal paket pyspark, findspark, pandas, dan matplotlib di Google Colab.
Inisialisasi findspark:

2. Menggunakan findspark.init() untuk menginisialisasi findspark dan menghubungkan PySpark ke Google Colab.
Membuat DataFrame:

3. DataFrame df_karyawan berisi informasi tentang karyawan (nama, pekerjaan, gaji, dan tanggal).
DataFrame df_proyek berisi informasi proyek yang dihubungkan dengan pekerjaan.
Join DataFrame:

4. Menggabungkan df_karyawan dan df_proyek berdasarkan kolom pekerjaan menggunakan fungsi join.
Memisahkan Kolom Tanggal:

5. Memisahkan kolom tanggal menjadi Hari, Bulan, dan Tahun menggunakan fungsi split.
GroupBy dan Agregasi: 

6. Menggunakan groupBy untuk mengelompokkan data berdasarkan pekerjaan dan menghitung rata-rata gaji.
Visualisasi dengan Matplotlib:

7. Data hasil groupBy dikonversi menjadi DataFrame Pandas dan kemudian divisualisasikan menggunakan matplotlib.
Menampilkan Hasil:










ChatGPT dapat membuat kesalahan. Perik
